<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FReNeRF estimate camera pose from a single image and a NeRF model, without any pose prior">
  <meta name="keywords" content="FreNeRF, NeRF, pose estimation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FReNeRF</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-3PFZBJX7MJ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-3PFZBJX7MJ');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans"
        rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script> -->
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <!-- <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script> -->
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FReNeRF: Initialization-free 6DoF pose estimation from a single image and a NeRF model</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=aGhFCssAAAAJ" target="_blank">Matteo Bortolon</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=cG-YBGcAAAAJ" target="_blank">Theodore Tsesmelis</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=z3R9FfMAAAAJ" target="_blank">Stuart James</a><sup>1,4</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=BQ7li6AAAAAJ" target="_blank">Fabio Poiesi</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=LUzvbGIAAAAJ" target="_blank">Alessio Del Bue</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block logo-img"><sup>1</sup><img src="./static/logos/pavis.png">,</span>
            <span class="author-block logo-img"><sup>2</sup><img src="./static/logos/fbk.jpg">,</span>
            <span class="author-block logo-img"><sup>3</sup><img src="./static/logos/unitn.png">,</span>
            <span class="author-block logo-img"><sup>4</sup><img src="./static/logos/durham.png"></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=0zyIo_e_6lo"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->

              <span class="link-block">
                <a class="external-link button is-normal is-rounded is-dark is-grey" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container">
    <div class="hero-body has-text-centered">
      <figure class="is-inline-block is-max-tablet">
        <img src="./static/images/ICRA_Teaser.png">
      </figure>
      <h2 class="subtitle has-text-centered">
        From <em>(i)</em> a given image with an unknown pose and <em>(ii)</em> a NeRF model, we recover the pose by first <em>(iii)</em> sampling surface points using Metropolis-Hasting algorithm and <em>(iv)</em> casting rays from them in isocell distribution. We then <em>(iv/v)</em> correlate rays with the image to identify relevant rays using attention and <em>(vii)</em> recover the unknown camera pose.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce <em>FReNeRF</em> to estimate the camera pose of a given image, building on the neural radiance fields (NeRF) formulation.
            <em>FReNeRF</em> is specifically designed to operate in real-time and eliminates the need for an initial pose guess that is proximate to the sought solution.
          </p>
          <p>
            <em>FReNeRF</em> utilizes the Metropolis-Hasting algorithm to sample surface points from within the NeRF model.
            From these sampled points, we cast rays and deduce the color for each ray through pixel-level view synthesis.
            The camera pose can then be estimated as the solution to a Least Squares problem by selecting correspondences between the query image and the resulting bundle.
            We facilitate this process through a learned attention mechanism, bridging the query image embedding with the embedding of parameterized rays, thereby matching rays pertinent to the image.
          </p>
          <p>
            Through synthetic and real evaluation settings, we show that our method can improve the angular and translation error accuracy by <strong>80.1%</strong> and <strong>67.3%</strong>, respectively, compared to iNeRF while not requiring the initial pose guess and performing at <strong>34fps</strong> on consumer hardware.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/0zyIo_e_6lo?si=Y2BhOrFAeDbwG49d?si=XNHG6uht8nGs_Q1T&rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <figure class="is-inline-block">
          <img src="./static/images/ICRA_Fig2_Final.png">
        </figure>
        <div class="content has-text-justified">
          <p>
            <em>FReNeRF</em> aims to predict the camera pose given an observed image and a pre-computed NeRF model.
            We firstly apply a Metropolis-Hastings algorithm to sample surface points within the scene volume, then we cast a set rays from an isocell at each surface point.
            We then learn an attention map between embeddings of the image and generated rays.
            Based on the information contained in the attention map, we select a subset of candidate rays that are likely to fall within the image.
            Finally, to recover the camera at test time, we optimize using Least Squares over the selected rays.
          </p>
        </div>
      </div>
    </div>
    <!--/ Method. -->
  </div>
</section>

<!-- Results. -->
<section class="section">
  <div class="container is-max-desktop">
    
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        <div class="content has-text-justified">
          <p>
            Qualitative results on two datasets, each figure depicts the target images (left up) and their corresponding NVS (left down) based on the camera poses, as these were estimated from PEGasuS (on the right of each scene).
            The NVS of each scene is rendered based on the given 3DGS model.
            The 3DGS model for each scene is displayed as sub-sampled points deriving from the corresponding ellipsoid centroids.
            The color of the camera indicates the tested configuration as seen below.
          </p>
        </div>
        <h2 class="subtitle is-8"><b>Camera configurations</b></h2>
        <div class="columns is-size-7 result-legend pb-3">
          <div class="column">
            <figure class="">
              <img src="./static/images/qualitative_visualization/cameras/gt.png">
              <figcaption>Ground Truth</figcaption>
            </figure>
          </div>
          <div class="column">
            <figure class="">
              <img src="./static/images/qualitative_visualization/cameras/ours.png">
              <figcaption>FReNeRF</figcaption>
            </figure>
          </div>
          <div class="column">
            <figure class="">
              <img src="./static/images/qualitative_visualization/cameras/nemo_voge_random.png">
              <figcaption>iNeRF with pose prior</figcaption>
            </figure>
          </div>
          <div class="column">
            <figure class="">
              <img src="./static/images/qualitative_visualization/cameras/inerf_random.png">
              <figcaption>iNeRF without pose prior</figcaption>
            </figure>
          </div>
        </div>
        <hr class="mt-6"/>
        <h2 class="subtitle is-4 mt-5">Barn (Tanks &amp; Temples)</h2>
        <div class="columns is-mobile">
          <div class="column main-result-column">
            <figure class="image">
              <img src="./static/images/qualitative_visualization/barn_results.png">
            </figure>
          </div>
        </div>
        <hr class="mt-6"/>
        <h2 class="subtitle is-4 mt-5">Ignatius (Tanks &amp; Temples)</h2>
        <div class="columns is-mobile">
          <div class="column main-result-column vertical-result">
            <figure class="image">
              <img src="./static/images/qualitative_visualization/ignatius_results.png">
            </figure>
          </div>
        </div>
        <hr class="mt-6"/>
        <h2 class="subtitle is-4 mt-5">Ficus (NeRF-synthetic 360&#176;)</h2>
        <div class="columns is-mobile">
          <div class="column main-result-column">
            <figure class="image">
              <img src="./static/images/qualitative_visualization/ficus_results.png">
            </figure>
          </div>
        </div>
        <hr class="mt-6"/>
        <h2 class="subtitle is-4 mt-5">Ship (NeRF-synthetic 360&#176;)</h2>
        <div class="columns is-mobile">
          <div class="column main-result-column">
            <figure class="image">
              <img src="./static/images/qualitative_visualization/ship_results.png">
            </figure>
          </div>
        </div>
      </div>
      
    </div>
  </div>
</section>
<!--/ Results. -->


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{bortolon2024frenerf,
  title = {FReNeRF: Initialization-free 6DoF pose estimation from a single image and a NeRF model},
  author = {Bortolon, Matteo and Tsesmelis, Theodore and James, Stuart and Poiesi, Fabio and {Del Bue}, Alessio},
  journal = {ICRA},
  year = {2024}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-Share Alike 4.0 International License</a>.
            The webpage template is from <a href="https://nerfies.github.io/">Nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
